{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltools.data import Brain_Data\n",
    "from nltools.mask import expand_mask\n",
    "from bids import BIDSLayout, BIDSValidator\n",
    "\n",
    "#data_dir = '/mnt/chrastil/lab/users/lily/localizer_beta_series_run_trials_only'\n",
    "#data_dir = '/mnt/chrastil/lab/users/lily/localizer_beta_series_all_run_exploration'\n",
    "#data_dir = '/mnt/chrastil/lab/users/lily/localizer_beta_series_all_exploration'\n",
    "#data_dir = '/mnt/chrastil/lab/users/lily/path_direction/localizer_beta_series_run_trials_only'\n",
    "# data_dir = '/mnt/chrastil/lab/users/lily/path_direction/localizer_beta_series_all_exploration'\n",
    "data_dir = '/mnt/chrastil/lab/users/lily/path_direction/localizer_beta_series_all_run_exploration'\n",
    "\n",
    "layout = BIDSLayout(data_dir, derivatives=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltools.utils import get_resource_path\n",
    "from nltools.file_reader import onsets_to_dm\n",
    "from nltools.data import Design_Matrix\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_num = 'sub-043'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_file_list = glob.glob(os.path.join(data_dir, 'derivatives', 'nibetaseries',sub_num,'func','*Run*_desc-E*.nii.gz'))\n",
    "E_file_list.sort() \n",
    "E = Brain_Data(E_file_list)\n",
    "\n",
    "N_file_list = glob.glob(os.path.join(data_dir,  'derivatives', 'nibetaseries',sub_num,'func','*Run*_desc-N*.nii.gz'))\n",
    "N_file_list.sort()\n",
    "N = Brain_Data(N_file_list)\n",
    "\n",
    "W_file_list = glob.glob(os.path.join(data_dir, 'derivatives', 'nibetaseries',sub_num,'func','*Run*_desc-W*.nii.gz'))\n",
    "W_file_list.sort() \n",
    "W = Brain_Data(W_file_list)\n",
    "\n",
    "S_file_list = glob.glob(os.path.join(data_dir, 'derivatives', 'nibetaseries',sub_num,'func','*Run*_desc-S*.nii.gz'))\n",
    "S_file_list.sort() \n",
    "S = Brain_Data(S_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = E.append(N)\n",
    "data = data.append(W)\n",
    "data = data.append(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(E.data))\n",
    "print(len(N.data))\n",
    "print(len(W.data))\n",
    "print(len(S.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y = pd.DataFrame(np.hstack([np.zeros(157), np.ones(119),2*np.ones(122), 3*np.ones(97)]))\n",
    "Y = pd.DataFrame(np.hstack([np.zeros(len(E.data)), np.ones(len(N.data)),2*np.ones(len(W.data)), 3*np.ones(len(S.data))]))\n",
    "\n",
    "#Y = pd.DataFrame(np.hstack([np.zeros(42), np.ones(44)]))\n",
    "\n",
    "data.Y = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection - Whole Brain Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------\n",
    "# Define the prediction function to be used.\n",
    "# Here we use a Support Vector Classification, with a linear kernel\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel='linear')\n",
    "\n",
    "# Define the dimension reduction to be used.\n",
    "# Here we use a classical univariate feature selection based on F-test,\n",
    "# namely Anova. When doing full-brain analysis, it is better to use\n",
    "# SelectPercentile, keeping 5% of voxels\n",
    "# (because it is independent of the resolution of the data).\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "feature_selection = SelectPercentile(f_classif, percentile=5)\n",
    "\n",
    "# We have our classifier (SVC), our feature selection (SelectPercentile),and now,\n",
    "# we can plug them together in a *pipeline* that performs the two operations\n",
    "# successively:\n",
    "from sklearn.pipeline import Pipeline\n",
    "anova_svc = Pipeline([('anova', feature_selection), ('svc', svc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# Fit the decoder and predict\n",
    "# ----------------------------\n",
    "anova_svc.fit(data.data, data.Y.values.ravel())\n",
    "y_pred = anova_svc.predict(data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# Obtain prediction scores via cross validation\n",
    "# -----------------------------------------------\n",
    "from sklearn.model_selection import LeaveOneGroupOut, cross_val_score\n",
    "\n",
    "# Define the cross-validation scheme used for validation.\n",
    "# Here we use a LeaveOneGroupOut cross-validation on the session group\n",
    "# which corresponds to a leave-one-session-out\n",
    "#cv = LeaveOneGroupOut()\n",
    "\n",
    "\n",
    "# Compute the prediction accuracy for the different folds (i.e. session)\n",
    "#cv_scores = cross_val_score(anova_svc, data.data, data.Y, cv=cv, groups=4)\n",
    "cv_scores = cross_val_score(anova_svc, data.data, data.Y.values.ravel(), cv=5)\n",
    "\n",
    "# Return the corresponding mean prediction accuracy\n",
    "classification_accuracy = cv_scores.mean()\n",
    "\n",
    "# Print the results\n",
    "print(\"Classification accuracy: %.4f / Chance level: %f\" %\n",
    "      (classification_accuracy, 1. / len(data.Y[0].unique())))\n",
    "# Classification accuracy:  0.70370 / Chance level: 0.5000\n",
    "\n",
    "\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# roi - thalamus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_mni_file = os.path.join(data_dir,\n",
    "                              \"derivatives\",\n",
    "                              \"data\",\n",
    "                              \"HarvardOxford-sub-maxprob-thr25-1mm.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = Brain_Data(atlas_mni_file)\n",
    "mask_x = expand_mask(mask)\n",
    "\n",
    "f = mask.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index - 1 for all because this is python!!!\n",
    "tha = mask_x[[4-1,15-1]].sum() # thalamus\n",
    "\n",
    "data_masked = data.apply_mask(tha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_svc = Pipeline([('anova', feature_selection), ('svc', svc)])\n",
    "anova_svc.fit(data_masked.data, data_masked.Y.values.ravel())\n",
    "y_pred = anova_svc.predict(data_masked.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = cross_val_score(anova_svc, data_masked.data, data_masked.Y.values.ravel(), cv=5)\n",
    "\n",
    "# Return the corresponding mean prediction accuracy\n",
    "classification_accuracy = cv_scores.mean()\n",
    "\n",
    "# Print the results\n",
    "print(\"Classification accuracy: %.4f / Chandata_maskedce level: %f\" %\n",
    "      (classification_accuracy, 1. / len(data.Y[0].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# new algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold, LeaveOneOut, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_masked.data\n",
    "Y = data_masked.Y.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loo = LeaveOneOut()\n",
    "X_std = MinMaxScaler().fit_transform(X)\n",
    "svc = SVC(kernel = \"rbf\",C = 0.001, gamma = 0.001)\n",
    "\n",
    "cv_scores = cross_val_score(svc, X_std, Y, cv= loo, n_jobs = -1)\n",
    "\n",
    "classification_accuracy = cv_scores.mean()\n",
    "print(classification_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import permutation_test_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_svc = Pipeline([('anova', feature_selection), ('svc', SVC(kernel = \"linear\"))])\n",
    "\n",
    "null_cv_scores, value2, value3 = permutation_test_score(\n",
    "    anova_svc, X, Y, scoring=\"accuracy\", cv=loo,  n_jobs = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(null_cv_scores)\n",
    "print(value2)\n",
    "print(value3)\n",
    "\n",
    "value2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.hist(value2, bins=20, density=True)\n",
    "ax.axvline(null_cv_scores, ls='--', color='r')\n",
    "score_label = (f\"Score on original\\ndata: {null_cv_scores:.2f}\\n\"\n",
    "               f\"(p-value: {value3:.3f})\")\n",
    "ax.text(0.7, 260, score_label, fontsize=12)\n",
    "ax.set_xlabel(\"Accuracy score\")\n",
    "_ = ax.set_ylabel(\"Probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROI - Retrosplenial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atlas_mni_file = os.path.join(data_dir,\n",
    "#                               \"derivatives\",\n",
    "#                               \"data\",\n",
    "#                               \"Schaefer2018_100Parcels_17Networks_order_FSLMNI152_1mm.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = Brain_Data(atlas_mni_file)\n",
    "# mask_x = expand_mask(mask)\n",
    "\n",
    "# f = mask.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # index - 1 for all because this is python!!!\n",
    "# rsc = mask_x[[48-1,96-1]].sum() # retrosplenial cortex\n",
    "\n",
    "# data_masked = data.apply_mask(rsc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anova_svc = Pipeline([('anova', feature_selection), ('svc', svc)])\n",
    "# anova_svc.fit(data_masked.data, data_masked.Y.values.ravel())\n",
    "# y_pred = anova_svc.predict(data_masked.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_scores = cross_val_score(anova_svc, data_masked.data, data_masked.Y.values.ravel(), cv=5)\n",
    "\n",
    "# # Return the corresponding mean prediction accuracy\n",
    "# classification_accuracy = cv_scores.mean()\n",
    "\n",
    "# # Print the results\n",
    "# print(\"Classification accuracy: %.4f / Chandata_maskedce level: %f\" %\n",
    "#       (classification_accuracy, 1. / len(data.Y[0].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROI - Precuneus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # index - 1 for all because this is python!!!\n",
    "# pcun = mask_x[[35-1,36-1]].sum() # precuneus\n",
    "\n",
    "# data_masked = data.apply_mask(pcun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anova_svc = Pipeline([('anova', feature_selection), ('svc', svc)])\n",
    "# anova_svc.fit(data_masked.data, data_masked.Y.values.ravel())\n",
    "# y_pred = anova_svc.predict(data_masked.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_scores = cross_val_score(anova_svc, data_masked.data, data_masked.Y.values.ravel(), cv=5)\n",
    "\n",
    "# # Return the corresponding mean prediction accuracy\n",
    "# classification_accuracy = cv_scores.mean()\n",
    "\n",
    "# # Print the results\n",
    "# print(\"Classification accuracy: %.4f / Chandata_maskedce level: %f\" %\n",
    "#       (classification_accuracy, 1. / len(data.Y[0].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROI - Medial Parietal Lobe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # index - 1 for all because this is python!!!\n",
    "\n",
    "# mpar = mask_x[[24-1,73-1]].sum() # medial parietal lobe\n",
    "\n",
    "# data_masked = data.apply_mask(mpar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anova_svc = Pipeline([('anova', feature_selection), ('svc', svc)])\n",
    "# anova_svc.fit(data_masked.data, data_masked.Y.values.ravel())\n",
    "# y_pred = anova_svc.predict(data_masked.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_scores = cross_val_score(anova_svc, data_masked.data, data_masked.Y.values.ravel(), cv=5)\n",
    "\n",
    "# # Return the corresponding mean prediction accuracy\n",
    "# classification_accuracy = cv_scores.mean()\n",
    "\n",
    "# # Print the results\n",
    "# print(\"Classification accuracy: %.4f / Chandata_maskedce level: %f\" %\n",
    "#       (classification_accuracy, 1. / len(data.Y[0].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROI - Intraparietal Sulcus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # index - 1 for all because this is python!!!\n",
    "\n",
    "# ips = mask_x[[31-1,80-1]].sum() # intrapariental sulcus\n",
    "\n",
    "# data_masked = data.apply_mask(ips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anova_svc = Pipeline([('anova', feature_selection), ('svc', svc)])\n",
    "# anova_svc.fit(data_masked.data, data_masked.Y.values.ravel())\n",
    "# y_pred = anova_svc.predict(data_masked.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_scores = cross_val_score(anova_svc, data_masked.data, data_masked.Y.values.ravel(), cv=5)\n",
    "\n",
    "# # Return the corresponding mean prediction accuracy\n",
    "# classification_accuracy = cv_scores.mean()\n",
    "\n",
    "# # Print the results\n",
    "# print(\"Classification accuracy: %.4f / Chandata_maskedce level: %f\" %\n",
    "#       (classification_accuracy, 1. / len(data.Y[0].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROI - Extrastriate Cortex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # index - 1 for all because this is python!!!\n",
    "\n",
    "# ext = mask_x[[1-1,2-1,4-1,51-1,52-1,53-1]].sum() # extrastriate cortex\n",
    "\n",
    "# data_masked = data.apply_mask(ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anova_svc = Pipeline([('anova', feature_selection), ('svc', svc)])\n",
    "# anova_svc.fit(data_masked.data, data_masked.Y.values.ravel())\n",
    "# y_pred = anova_svc.predict(data_masked.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_scores = cross_val_score(anova_svc, data_masked.data, data_masked.Y.values.ravel(), cv=5)\n",
    "\n",
    "# # Return the corresponding mean prediction accuracy\n",
    "# classification_accuracy = cv_scores.mean()\n",
    "\n",
    "# # Print the results\n",
    "# print(\"Classification accuracy: %.4f / Chandata_maskedce level: %f\" %\n",
    "#       (classification_accuracy, 1. / len(data.Y[0].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROI - Parahippocampus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # index - 1 for all because this is python!!!\n",
    "\n",
    "# phc = mask_x[[49-1,97-1]].sum() # parahippocampus\n",
    "\n",
    "\n",
    "# data_masked = data.apply_mask(phc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anova_svc = Pipeline([('anova', feature_selection), ('svc', svc)])\n",
    "# anova_svc.fit(data_masked.data, data_masked.Y.values.ravel())\n",
    "# y_pred = anova_svc.predict(data_masked.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_scores = cross_val_score(anova_svc, data_masked.data, data_masked.Y.values.ravel(), cv=5)\n",
    "\n",
    "# # Return the corresponding mean prediction accuracy\n",
    "# classification_accuracy = cv_scores.mean()\n",
    "\n",
    "# # Print the results\n",
    "# print(\"Classification accuracy: %.4f / Chandata_maskedce level: %f\" %\n",
    "#       (classification_accuracy, 1. / len(data.Y[0].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROI - Somatomotor Cortex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index - 1 for all because this is python!!!\n",
    "\n",
    "# som = mask_x[[8-1,9-1,10-1,11-1,12-1,13-1,57-1,58-1,59-1,60-1,61-1,62-1,63-1,64-1]].sum() # somatomotor\n",
    "\n",
    "\n",
    "\n",
    "# data_masked = data.apply_mask(som)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anova_svc = Pipeline([('anova', feature_selection), ('svc', svc)])\n",
    "# anova_svc.fit(data_masked.data, data_masked.Y.values.ravel())\n",
    "# y_pred = anova_svc.predict(data_masked.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_scores = cross_val_score(anova_svc, data_masked.data, data_masked.Y.values.ravel(), cv=5)\n",
    "\n",
    "# # Return the corresponding mean prediction accuracy\n",
    "# classification_accuracy = cv_scores.mean()\n",
    "\n",
    "# # Print the results\n",
    "# print(\"Classification accuracy: %.4f / Chandata_maskedce level: %f\" %\n",
    "#       (classification_accuracy, 1. / len(data.Y[0].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROI - Temporal + Temporoparietal lobe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # index - 1 for all because this is python!!!\n",
    "\n",
    "# temp = mask_x[[41-1,42-1,50-1, 98-1,99-1,100-1]].sum() # temporal lobe, temporal parietal lobe\n",
    "\n",
    "# data_masked = data.apply_mask(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anova_svc = Pipeline([('anova', feature_selection), ('svc', svc)])\n",
    "# anova_svc.fit(data_masked.data, data_masked.Y.values.ravel())\n",
    "# y_pred = anova_svc.predict(data_masked.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_scores = cross_val_score(anova_svc, data_masked.data, data_masked.Y.values.ravel(), cv=5)\n",
    "\n",
    "# # Return the corresponding mean prediction accuracy\n",
    "# classification_accuracy = cv_scores.mean()\n",
    "\n",
    "# # Print the results\n",
    "# print(\"Classification accuracy: %.4f / Chandata_maskedce level: %f\" %\n",
    "#       (classification_accuracy, 1. / len(data.Y[0].unique())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
